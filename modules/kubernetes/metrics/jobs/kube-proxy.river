/*
Module: job-kube-proxy
Description: Kube Proxy

Note: Every argument except for "forward_to" is optional, and does have a defined default value.  However, the values for these
      arguments are not defined using the default = " ... " argument syntax, but rather using the coalesce(argument.value, " ... ").
      This is because if the argument passed in from another consuming module is set to null, the default = " ... " syntax will
      does not override the value passed in, where coalesce() will return the first non-null value.
*/
argument "forward_to" {
  comment = "Must be a list(MetricsReceiver) where collected logs should be forwarded to"
  optional = false
}

argument "enabled" {
  comment = "Whether or not the kube-proxy job should be enabled, this is useful for disabling the job when it is being consumed by other modules in a multi-tenancy environment"
  optional = true
}

argument "namespace" {
  comment = "The namespace to look for targets in (default: kube-system)"
  optional = true
}

argument "selectors" {
  // see: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  comment = "The label selectors to use to find matching targets (default: [\"component=kube-proxy\"])"
  optional = true
}

argument "port" {
  comment = "The port to scrape kube-proxy metrics on"
  optional = true
}

argument "job_label" {
  comment = "The job label to add for all kube-proxy metrics"
  optional = true
}

argument "keep_metrics" {
  comment = "A regex of metrics to keep (default: see below)"
  optional = true
}

argument "scrape_interval" {
  comment = "How often to scrape metrics from the targets (default: 60s)"
  optional = true
}

argument "max_cache_size" {
  comment = "The maximum number of elements to hold in the relabeling cache (default: 100000).  Only increase if the amount of metrics returned is extremely large, the default will almost always be sufficient"
  optional = true
}

argument "clustering" {
  // Docs: https://grafana.com/docs/agent/latest/flow/concepts/clustering/
  comment = "Whether or not clustering should be enabled (default: false)"
  optional = true
}

// kube-proxy service discovery for all of the pods in the kube_proxy daemonset
discovery.kubernetes "kube_proxy" {
  role = "pod"

  selectors {
    role = "pod"
    label = join(coalesce(argument.selectors.value, ["component=kube-proxy"]), ",")
  }

  namespaces {
    names = [coalesce(argument.namespace.value, "kube-system")]
  }
}

// kube_proxy relabelings (pre-scrape)
discovery.relabel "kube_proxy" {
  targets = discovery.kubernetes.kube_proxy.targets

  // drop all targets if enabled is false
  rule {
    target_label = "__enabled"
    replacement = format("%s", coalesce(argument.enabled.value, "true"))
  }
  rule {
    source_labels = ["__enabled"]
    regex = "false"
    action = "drop"
  }

  rule {
    source_labels = ["__address__"]
    replacement = "$1:" + format("%s", coalesce(argument.port.value, "10249"))
    target_label = "__address__"
  }
}

// kube_proxy scrape job
prometheus.scrape "kube_proxy" {
  job_name = coalesce(argument.job_label.value, "integrations/kubernetes/kube-proxy")
  forward_to = [prometheus.relabel.kube_proxy.receiver]
  targets = discovery.relabel.kube_proxy.output
  scrape_interval = coalesce(argument.scrape_interval.value, "60s")

  clustering {
    enabled = coalesce(argument.clustering.value, false)
  }
}

// kube-proxy metric relabelings (post-scrape)
prometheus.relabel "kube_proxy" {
  forward_to = argument.forward_to.value
  max_cache_size = coalesce(argument.max_cache_size.value, 100000)

  // keep only metrics that match the keep_metrics regex
  rule {
    source_labels = ["__name__"]
    regex = coalesce(argument.keep_metrics.value, "(.+)")
    action = "keep"
  }
}

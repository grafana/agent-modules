/*
Module: job-node-exporter
Description: Scrapes Node Exporter, this is a separate scrape job, if you are also using annotation based scraping, you will want to explicitly
             disable node-exporter from being scraped by this module and annotations by setting the following annotation on the node-exporter
             metrics.agent.grafana.com/scrape: "false".

             Node exporter should be deployed as a DaemonSet, each pod on each worker will be scraped by the agent using endpoint service discovery
*/
argument "forward_to" {
  comment = "Must be a list(MetricsReceiver) where collected logs should be forwarded to"
  optional = false
}

argument "namespaces" {
  comment = "The namespaces to look for targets in"
  optional = true
  default = [] // [] is all namespaces
}

argument "selectors" {
  // see: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  comment = "The label selectors to use to find matching targets"
  optional = true
  default = [
    "app.kubernetes.io/name=prometheus-node-exporter",
  ]
}

argument "port_name" {
  comment = "The of the port to scrape metrics from"
  optional = true
  default = "metrics"
}

argument "job_label" {
  comment = "The job label to add for all node-exporter metrics"
  optional = true
  default = "integrations/node_exporter"
}

argument "keep_metrics" {
  comment = "A regex of metrics to keep"
  optional = true
  default = "(up|node_cpu.*|node_exporter_build_info|node_filesystem.*|node_memory.*|process_cpu_seconds_total|process_resident_memory_bytes)"
}

argument "scrape_interval" {
  comment = "How often to scrape metrics from the targets"
  optional = true
  default = "60s"
}

argument "max_cache_size" {
  comment = "The maximum number of elements to hold in the relabeling cache.  Only increase if the amount of metrics returned is extremely large, the default will almost always be sufficient."
  optional = true
  default = 100000
}

argument "clustering" {
  comment = "Whether or not clustering should be enabled"
  optional = true
  default = false
}

// node exporter service discovery for all of the pods in the node exporter daemonset
discovery.kubernetes "node_exporter" {
  role = "pod"

  selectors {
    role = "pod"
    label = join(argument.selectors.value, ",")
  }

  namespaces {
    names = argument.namespaces.value
  }
}

// node exporter relabelings (pre-scrape)
discovery.relabel "node_exporter" {
  targets = discovery.kubernetes.node_exporter.targets

  // keep only the specified metrics port name, and pods that are Running and ready
  rule {
    source_labels = [
      "__meta_kubernetes_pod_container_port_name",
      "__meta_kubernetes_pod_phase",
      "__meta_kubernetes_pod_ready",
    ]
    separator = "@"
    regex = argument.port_name.value + "@Running@true"
    action = "keep"
  }

  // copy the pod name to the instance label
  rule {
    source_labels = ["__meta_kubernetes_pod_node_name"]
    action = "replace"
    target_label = "instance"
  }
}

// node exporter scrape job
prometheus.scrape "node_exporter" {
  job_name = argument.job_label.value
  forward_to = [prometheus.relabel.node_exporter.receiver]
  targets = discovery.relabel.node_exporter.output
  scrape_interval = argument.scrape_interval.value

  clustering {
    enabled = argument.clustering.value
  }
}

// node-exporter metric relabelings (post-scrape)
prometheus.relabel "node_exporter" {
  forward_to = argument.forward_to.value
  max_cache_size = argument.max_cache_size.value

  // keep only metrics that match the keep_metrics regex
  rule {
    source_labels = ["__name__"]
    regex = argument.keep_metrics.value
    action = "keep"
  }

  // Drop metrics for certain file systems
  rule {
    source_labels = ["__name__", "fstype"]
    separator = "@"
    regex = "node_filesystem.*@(tempfs)"
    action = "drop"
  }
}

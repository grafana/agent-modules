/*
Module: job-agent
Description: Scrapes grafana agent

Note: Every argument except for "forward_to" is optional, and does have a defined default value.  However, the values for these
      arguments are not defined using the default = " ... " argument syntax, but rather using the coalesce(argument.value, " ... ").
      This is because if the argument passed in from another consuming module is set to null, the default = " ... " syntax will
      does not override the value passed in, where coalesce() will return the first non-null value.

Usage:
// import the module
import.git "agent" {
  repository = "https://github.com/grafana/agent-modules.git"
  revision   = "main"
  path       = "modules/kubernetes/logs/kubelet.river"
  pull_frequency = "15m"
}

// if on kubernetes
agent.kubernetes "metrics" {
  forward_to = [prometheus.remote_write.default.receiver]
}

// if on local machine / vm
agent.local "metrics" {
  forward_to = [prometheus.remote_write.default.receiver]
}
*/
declare "kubernetes" {
  // arguments for kubernetes discovery
  argument "namespaces" {
    comment = "The namespaces to look for targets in (default: [] is all namespaces)"
    optional = true
  }

  argument "selectors" {
    // Docs: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
    comment = "The label selectors to use to find matching targets (default: [\"app.kubernetes.io/name=grafana-agent\"])"
    optional = true
  }

  argument "port_name" {
    comment = "The of the port to scrape metrics from (default: http-metrics)"
    optional = true
  }

  // arguments for scrape module
  argument "forward_to" {
    comment = "Must be a list(MetricsReceiver) where collected logs should be forwarded to"
  }

  argument "job_label" {
    comment = "The job label to add for all grafana-agent metric (default: integrations/agent)"
    optional = true
  }

  argument "keep_metrics" {
    comment = "A regex of metrics to keep (default: see below)"
    optional = true
  }

  argument "scrape_interval" {
    comment = "How often to scrape metrics from the targets (default: 60s)"
    optional = true
  }

  argument "scrape_timeout" {
    comment = "How long before a scrape times out (default: 10s)"
    optional = true
  }

  argument "max_cache_size" {
    comment = "The maximum number of elements to hold in the relabeling cache (default: 100000).  This should be at least 2x-5x your largest scrape target or samples appended rate."
    optional = true
  }

  argument "clustering" {
    // Docs: https://grafana.com/docs/agent/latest/flow/concepts/clustering/
    comment = "Whether or not clustering should be enabled (default: false)"
    optional = true
  }

  // grafana agent service discovery for all of the pods in the grafana agent daemonset
  discovery.kubernetes "agent" {
    role = "pod"

    selectors {
      role = "pod"
      label = join(coalesce(argument.selectors.value, ["app.kubernetes.io/name=grafana-agent"]), ",")
    }

    namespaces {
      names = coalesce(argument.namespaces.value, [])
    }
  }

  // grafana agent relabelings (pre-scrape)
  discovery.relabel "Kubernetes" {
    targets = discovery.kubernetes.agent.targets

    // keep only the specified metrics port name, and pods that are Running and ready
    rule {
      source_labels = [
        "__meta_kubernetes_pod_container_port_name",
        "__meta_kubernetes_pod_phase",
        "__meta_kubernetes_pod_ready",
      ]
      separator = "@"
      regex = coalesce(argument.port_name.value, "http-metrics") + "@Running@true"
      action = "keep"
    }

    // set the namespace label
    rule {
      source_labels = ["__meta_kubernetes_namespace"]
      target_label  = "namespace"
    }

    // set the pod label
    rule {
      source_labels = ["__meta_kubernetes_pod_name"]
      target_label  = "pod"
    }

    // set the container label
    rule {
      source_labels = ["__meta_kubernetes_pod_container_name"]
      target_label  = "container"
    }

    // set a workload label
    rule {
      source_labels = [
        "__meta_kubernetes_pod_controller_kind",
        "__meta_kubernetes_pod_controller_name",
      ]
      separator = "/"
      target_label  = "workload"
    }

    // set the app name if specified as metadata labels "app:" or "app.kubernetes.io/name:" or "k8s-app:"
    rule {
      action = "replace"
      source_labels = [
        "__meta_kubernetes_pod_label_app_kubernetes_io_name",
        "__meta_kubernetes_pod_label_k8s_app",
        "__meta_kubernetes_pod_label_app",
      ]
      separator = ";"
      regex = "^(?:;*)?([^;]+).*$"
      replacement = "$1"
      target_label = "app"
    }
  }

  // invoke common scrape module
  scrape "job" {
    forward_to = argument.forward_to.value
    targets = discovery.relabel.kubernetes.output
    job_label = coalesce(argument.job_label.value, "integrations/agent")
    keep_metrics = coalesce(argument.keep_metrics.value, null)
    scrape_interval = coalesce(argument.scrape_interval.value, "60s")
    scrape_timeout = coalesce(argument.scrape_timeout.value, "10s")
    max_cache_size = coalesce(argument.max_cache_size.value, 100000)
    clustering = coalesce(argument.clustering.value, false)
  }
}

declare "local" {
  // arguments for local (static)
  argument "enabled" {
    comment = "Whether or not the grafana-agent job should be enabled, this is useful for disabling the job when it is being consumed by other modules in a multi-tenancy environment (default: true)"
    optional = true
  }

  // arguments for scrape module
  argument "forward_to" {
    comment = "Must be a list(MetricsReceiver) where collected logs should be forwarded to"
  }

  argument "job_label" {
    comment = "The job label to add for all grafana-agent metric (default: integrations/agent)"
    optional = true
  }

  argument "keep_metrics" {
    comment = "A regex of metrics to keep (default: see below)"
    optional = true
  }

  argument "scrape_interval" {
    comment = "How often to scrape metrics from the targets (default: 60s)"
    optional = true
  }

  argument "scrape_timeout" {
    comment = "How long before a scrape times out (default: 10s)"
    optional = true
  }

  argument "max_cache_size" {
    comment = "The maximum number of elements to hold in the relabeling cache (default: 100000).  This should be at least 2x-5x your largest scrape target or samples appended rate."
    optional = true
  }

  argument "clustering" {
    // Docs: https://grafana.com/docs/agent/latest/flow/concepts/clustering/
    comment = "Whether or not clustering should be enabled (default: false)"
    optional = true
  }

  discovery.relabel "local" {
    targets = [
      {
        "__address__" = "localhost:12345",
        "source" = "local"
      },
    ]
  }

  // invoke common scrape module
  scrape "job" {
    forward_to = argument.forward_to.value
    targets = discovery.relabel.local.output
    job_label = coalesce(argument.job_label.value, "integrations/agent")
    keep_metrics = coalesce(argument.keep_metrics.value, null)
    scrape_interval = coalesce(argument.scrape_interval.value, "60s")
    scrape_timeout = coalesce(argument.scrape_timeout.value, "10s")
    max_cache_size = coalesce(argument.max_cache_size.value, 100000)
    clustering = coalesce(argument.clustering.value, false)
  }
}

declare "scrape" {
  argument "forward_to" {
    comment = "Must be a list(MetricsReceiver) where collected logs should be forwarded to"
  }

  argument "targets" {
    comment = "Must be a list() of targets"
  }

  argument "job_label" {
    comment = "The job label to add for all grafana-agent metric (default: integrations/agent)"
    optional = true
  }

  argument "keep_metrics" {
    comment = "A regex of metrics to keep (default: see below)"
    optional = true
  }

  argument "scrape_interval" {
    comment = "How often to scrape metrics from the targets (default: 60s)"
    optional = true
  }

  argument "scrape_timeout" {
    comment = "How long before a scrape times out (default: 10s)"
    optional = true
  }

  argument "max_cache_size" {
    comment = "The maximum number of elements to hold in the relabeling cache (default: 100000).  This should be at least 2x-5x your largest scrape target or samples appended rate."
    optional = true
  }

  argument "clustering" {
    // Docs: https://grafana.com/docs/agent/latest/flow/concepts/clustering/
    comment = "Whether or not clustering should be enabled (default: false)"
    optional = true
  }

  // grafana agent scrape job
  prometheus.scrape "agent" {
    job_name = coalesce(argument.job_label.value, "integrations/agent")
    forward_to = [prometheus.relabel.agent.receiver]
    targets = argument.targets.value
    scrape_interval = coalesce(argument.scrape_interval.value, "60s")
    scrape_timeout = coalesce(argument.scrape_timeout.value, "10s")

    clustering {
      enabled = coalesce(argument.clustering.value, false)
    }
  }

  // grafana-agent metric relabelings (post-scrape)
  prometheus.relabel "agent" {
    forward_to = argument.forward_to.value
    max_cache_size = coalesce(argument.max_cache_size.value, 100000)

    // keep only metrics that match the keep_metrics regex
    rule {
      source_labels = ["__name__"]
      regex = coalesce(argument.keep_metrics.value, "(up|log_.+|(agent_(build_info|tcp_connections|wal_(samples_appended_total|storage_active_series))|go_(gc_duration_seconds_count|goroutines|memstats_heap_inuse_bytes)|process_(cpu_seconds_total|start_time_seconds)|prometheus_(remote_storage_(enqueue_retries_total|highest_timestamp_in_seconds|queue_highest_sent_timestamp_seconds|samples_(dropped_total|failed_total|pending|retried_total|total)|sent_batch_duration_seconds_(bucket|count|sum)|shard_(capacity|s(_desired|_max|_min))|succeeded_samples_total)|sd_discovered_targets|target_(interval_length_seconds_(count|sum)|scrapes_(exceeded_sample_limit_total|sample_(duplicate_timestamp_total|out_of_bounds_total|out_of_order_total)))|target_sync_length_seconds_sum|wal_watcher_current_segment)|traces_(exporter_send_failed_spans|exporter_sent_spans|loadbalancer_(backend_outcome|num_backends)|receiver_(accepted_spans|refused_spans))))")
      action = "keep"
    }

    // remove the component_id label from any metric that starts with log_bytes or log_lines, these are custom metrics that are generated
    // as part of the log annotation modules in this repo
    rule {
      action = "replace"
      source_labels = ["__name__"]
      regex = "^log_(bytes|lines).+"
      replacement = ""
      target_label = "component_id"
    }

    // set the namespace label to that of the exported_namespace
    rule {
      action = "replace"
      source_labels = ["__name__", "exported_namespace"]
      separator = "@"
      regex = "^log_(bytes|lines).+@(.+)"
      replacement = "$2"
      target_label = "namespace"
    }

    // set the pod label to that of the exported_pod
    rule {
      action = "replace"
      source_labels = ["__name__", "exported_pod"]
      separator = "@"
      regex = "^log_(bytes|lines).+@(.+)"
      replacement = "$2"
      target_label = "pod"
    }

    // set the container label to that of the exported_container
    rule {
      action = "replace"
      source_labels = ["__name__", "exported_container"]
      separator = "@"
      regex = "^log_(bytes|lines).+@(.+)"
      replacement = "$2"
      target_label = "container"
    }

    // set the job label to that of the exported_job
    rule {
      action = "replace"
      source_labels = ["__name__", "exported_job"]
      separator = "@"
      regex = "^log_(bytes|lines).+@(.+)"
      replacement = "$2"
      target_label = "job"
    }

    // set the instance label to that of the exported_instance
    rule {
      action = "replace"
      source_labels = ["__name__", "exported_instance"]
      separator = "@"
      regex = "^log_(bytes|lines).+@(.+)"
      replacement = "$2"
      target_label = "instance"
    }

    rule {
      action = "labeldrop"
      regex = "exported_(namespace|pod|container|job|instance)"
    }
  }
}
